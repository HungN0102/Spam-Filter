{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are going to build a spam filter using Supervised, multinomial Naive Bayes Algorithm. Our goal is to design a program that can classify spam and non-spam messages that have accuracy of more than 90%. \n",
    "\n",
    "We shall use the dataset that contained 5572 classified messages. You can download from <a hruf='https://archive.ics.uci.edu/ml/datasets/sms+spam+collection'>here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Text Classifier.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first shall import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:42.882518Z",
     "start_time": "2020-10-13T17:42:41.634511Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:42.930511Z",
     "start_time": "2020-10-13T17:42:42.882518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset has 5572 rows and 2 columns\n",
      "\n",
      "\n",
      "percentages of spam and ham messages\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "\n",
      "first 5 rows of the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection',sep='\\t',header=None)\n",
    "df.columns =['Label', 'SMS']\n",
    "\n",
    "print('Our dataset has',df.shape[0], 'rows and', df.shape[1],'columns')\n",
    "print('\\n')\n",
    "\n",
    "print('percentages of spam and ham messages')\n",
    "print(df['Label'].value_counts(normalize=True))\n",
    "\n",
    "print('\\n')\n",
    "print('first 5 rows of the dataset')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating our dataset in 2, training set and test set both respectively containing 80% and 20% of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:42.938515Z",
     "start_time": "2020-10-13T17:42:42.930511Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_random = df.sample(frac=1,random_state=1)\n",
    "split_index = round(len(data_random)*0.8)\n",
    "\n",
    "training_set = data_random[:split_index].reset_index(drop=True)\n",
    "test_set = data_random[split_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking percentages of spam and ham messages in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:42.950513Z",
     "start_time": "2020-10-13T17:42:42.938515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set\n",
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "\n",
      "test_set\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('training_set')\n",
    "print(training_set['Label'].value_counts(normalize=True))\n",
    "print('\\n')\n",
    "print('test_set')\n",
    "print(test_set['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step to train our algorithm is to clean our training set, our first step is to getting individual words in messages into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:43.006518Z",
     "start_time": "2020-10-13T17:42:42.950513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>[sorry, i, ll, call, later, in, meeting, any, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ham</td>\n",
       "      <td>[babe, i, fucking, love, you, too, you, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>spam</td>\n",
       "      <td>[u, ve, been, selected, to, stay, in, 1, of, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>[hello, my, boytoy, geeee, i, miss, you, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>ham</td>\n",
       "      <td>[wherre, s, my, boytoy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4458 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham                  [yep, by, the, pretty, sculpture]\n",
       "1      ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2      ham                    [welp, apparently, he, retired]\n",
       "3      ham                                           [havent]\n",
       "4      ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...\n",
       "...    ...                                                ...\n",
       "4453   ham  [sorry, i, ll, call, later, in, meeting, any, ...\n",
       "4454   ham  [babe, i, fucking, love, you, too, you, know, ...\n",
       "4455  spam  [u, ve, been, selected, to, stay, in, 1, of, 2...\n",
       "4456   ham  [hello, my, boytoy, geeee, i, miss, you, alrea...\n",
       "4457   ham                            [wherre, s, my, boytoy]\n",
       "\n",
       "[4458 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '\\W+'\n",
    "training_set['SMS'] = training_set['SMS'].str.replace(pattern, ' ').str.lower()\n",
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list that contains unique words from all of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:43.026515Z",
     "start_time": "2020-10-13T17:42:43.006518Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for row in training_set['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary that count number of occurence of each words in each messages. Then create a dataframe from this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:50.321144Z",
     "start_time": "2020-10-13T17:42:43.026515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arts</th>\n",
       "      <th>easy</th>\n",
       "      <th>soup</th>\n",
       "      <th>burger</th>\n",
       "      <th>l8rs</th>\n",
       "      <th>lot</th>\n",
       "      <th>roads</th>\n",
       "      <th>juswoke</th>\n",
       "      <th>drastic</th>\n",
       "      <th>goto</th>\n",
       "      <th>...</th>\n",
       "      <th>lst</th>\n",
       "      <th>ctxt</th>\n",
       "      <th>meg</th>\n",
       "      <th>arun</th>\n",
       "      <th>stomach</th>\n",
       "      <th>maretare</th>\n",
       "      <th>5wb</th>\n",
       "      <th>ennal</th>\n",
       "      <th>ki</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   arts  easy  soup  burger  l8rs  lot  roads  juswoke  drastic  goto  ...  \\\n",
       "0     0     0     0       0     0    0      0        0        0     0  ...   \n",
       "1     0     0     0       0     0    0      0        0        0     0  ...   \n",
       "2     0     0     0       0     0    0      0        0        0     0  ...   \n",
       "3     0     0     0       0     0    0      0        0        0     0  ...   \n",
       "4     0     0     0       0     0    0      0        0        0     0  ...   \n",
       "\n",
       "   lst  ctxt  meg  arun  stomach  maretare  5wb  ennal  ki  7  \n",
       "0    0     0    0     0        0         0    0      0   0  0  \n",
       "1    0     0    0     0        0         0    0      0   0  0  \n",
       "2    0     0    0     0        0         0    0      0   0  0  \n",
       "3    0     0    0     0        0         0    0      0   0  0  \n",
       "4    0     0    0     0        0         0    0      0   0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {unique_word: [0]*len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "wcps = pd.DataFrame(word_counts_per_sms)\n",
    "wcps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the new dataframe to the training set dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:50.485258Z",
     "start_time": "2020-10-13T17:42:50.321144Z"
    }
   },
   "outputs": [],
   "source": [
    "training_set_clean = pd.concat([training_set,wcps],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating dataset into 2 individual datasets, one contains spam messages while the other contains non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:42:50.717230Z",
     "start_time": "2020-10-13T17:42:50.485258Z"
    }
   },
   "outputs": [],
   "source": [
    "spam_sms = training_set_clean[training_set_clean['Label']=='spam']\n",
    "ham_sms = training_set_clean[training_set_clean['Label']=='ham']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:18:25.638117Z",
     "start_time": "2020-10-13T21:18:25.634128Z"
    }
   },
   "source": [
    "<img src='Formula.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first calculate parameters for the algorithms:\n",
    "- p_spam: probability of spam messages\n",
    "- p_ham: probability of ham messages\n",
    "- n_spam: total number of words in spam messages\n",
    "- n_ham: total number of words in ham messages\n",
    "- n_vocabulary: total_number of words in all messages\n",
    "- alpha: 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:24:33.961717Z",
     "start_time": "2020-10-13T21:24:33.954735Z"
    }
   },
   "outputs": [],
   "source": [
    "p_spam = len(spam_sms) / len(training_set_clean)\n",
    "p_ham = len(ham_sms) / len(training_set_clean)\n",
    "\n",
    "n_spam = spam_sms['SMS'].apply(len).sum()\n",
    "n_ham = ham_sms['SMS'].apply(len).sum()\n",
    "n_vocabulary = len(vocabulary)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating probabilities of each word occurences in both ham and spam messages.  P(wi|Spam) and P(wi|Ham) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:33:47.262559Z",
     "start_time": "2020-10-13T21:33:46.289229Z"
    }
   },
   "outputs": [],
   "source": [
    "spam_dict = {}\n",
    "ham_dict = {}\n",
    "for word in vocabulary:\n",
    "    spam_dict[word] = 0\n",
    "    ham_dict[word] = 0\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_word_in_spam = spam_sms[word].sum()\n",
    "    p_word_in_spam = (n_word_in_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    spam_dict[word] = p_word_in_spam\n",
    "    \n",
    "    n_word_in_ham = ham_sms[word].sum()\n",
    "    p_word_in_ham = (n_word_in_ham*alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    ham_dict[word] = p_word_in_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:34:36.332352Z",
     "start_time": "2020-10-13T21:34:36.329342Z"
    }
   },
   "source": [
    "<img src='Formula.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall write a function that can classify messages to spam and ham category. Here is a summary of each stages of our function.\n",
    "\n",
    "- Take in a message\n",
    "- Get each word of the message into a list of words\n",
    "- Calculating P(wi|Spam) and P(wi|Ham) \n",
    "- Comparing P(Spam| w1,w2,w3...) and P(Ham| w1,w2,w3...)\n",
    "\n",
    "\n",
    "- If P(Spam| w1,w2,w3...) > P(Ham| w1,w2,w3...) then return 'Spam'\n",
    "- If P(Spam| w1,w2,w3...) < P(Ham| w1,w2,w3...) then return 'Ham'\n",
    "- If P(Spam| w1,w2,w3...) = P(Ham| w1,w2,w3...) then return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:43:58.615877Z",
     "start_time": "2020-10-13T21:43:58.609893Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def classify(message):\n",
    "    message = re.sub('\\W',' ',message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "            \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is never a bad idea to test our function. We shall test it on our test_set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:45:35.273468Z",
     "start_time": "2020-10-13T21:45:34.246231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>But my family not responding for anything. Now...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>U too...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>Boo what time u get out? U were supposed to ta...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Genius what's up. How your brother. Pls send h...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>I liked the new mobile</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...      spam\n",
       "5   ham  But my family not responding for anything. Now...       ham\n",
       "6   ham                                           U too...       ham\n",
       "7   ham  Boo what time u get out? U were supposed to ta...       ham\n",
       "8   ham  Genius what's up. How your brother. Pls send h...       ham\n",
       "9   ham                             I liked the new mobile       ham"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify)\n",
    "test_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first 10 messages, we got 9 corrects out of 10. Which satisfied our goal for this project.\n",
    "However, it is better to have a better view to the accuracy of our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:53:18.153459Z",
     "start_time": "2020-10-13T21:53:18.147475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Spam Filter's accuracy is: 0.9488330341113106\n",
      "Total number of corrects is: 1057\n",
      "Total number of incorrects is: 57\n",
      "Number of messages tested is: 1114\n"
     ]
    }
   ],
   "source": [
    "total_correct = (test_set['predicted'] == test_set['Label']).sum()\n",
    "total = len(test_set)\n",
    "percentage_correct = total_correct / total\n",
    "print('Our Spam Filter\\'s accuracy is:', percentage_correct)\n",
    "print('Total number of corrects is:',total_correct)\n",
    "print('Total number of incorrects is:',total-total_correct)\n",
    "print('Number of messages tested is:', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result suggested that the accuracy of our filter had an accuracy of 95% on the test set we used. This has exceeded our initial goal, which is to get 90% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
